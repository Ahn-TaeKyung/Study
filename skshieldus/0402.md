# 생성형 AI
### 1. 생성형 AI 란?
- 생성형 인공지능 (Generative AI)은 프롬포트에 응답하여 텍스트, 이미지, 컴퓨터 코드, 콘텐츠를 생성할 수 있는 딥러닝 모델의 한 유형입니다.
- 생성형 AI는 머신 러닝의 한 유형으로 수학적 분석을 통해 관련 개념, 이미지, 패턴을 찾아내고, 이 분석을 사용하여 수신한 프롬포트와 통계적으로 유사하거나 관련성이 높은 콘텐츠를 생성합니다.
- 생성형 AI 모델로는 텍스트 생성을 위한 ChatGPT와 이미지 생성을 ㅜ이한 DALL-E가 있습니다.

### 2. 생성형 AI 장단점
#### 장점
- 할루시네이션(hallucination) 및 기타 부정확성: 생성형 AI 모델은 존재하지 않는 패턴을 식별하는 경우도 있습니다. 이로 인해 모델이 잘못된 정보를 제공할 수 있으며, 이러한 현상을 "할루시네이션"이라고 합니다.
  - 이를 보완 하기 위해 RAG가 많은 관심을 받고 있습니다.
- 데이터 유출: 모델은 프롬포트에서 제공된 데이터를 가져와 예상치 못한 상황에서 데이터를 노출시킬 수 있습니다. 여러 대기업에서 이 방식으로 기밀 정보나 소스 코드가 실수로 유출된 사례가 있습니다.
  - 이를 해결하기 위한 방안 중 하나로 ollama 등이 있습니다. (로컬에서 이용)
- 우발적인 표절 또는 지적 재산의 오용: 생성형 AI 모델은 기존 콘텐츠를 기반으로 하므로 해당 콘텐츠의 원저자나 저작권 소유자의 허가 없이 제공된 콘텐츠를 복제할 수 있습니다.
  - 현재 뉴욕타임즈 등 많은 기업들이 소송을버려 자신들의 재산권을 주장했고 인정받아 실제로 GPT의 정보의 질이 줄어들었다.
### 3. 대규모 언어 모델 (LLM)
- LLM (거대 언어모델, Large Language Model) 이란, 대용량의 언어 모델을 의미한다.
- LLM은 딥러닝 알고리즘과 통계 모델링을 통해 자연어 처리 작업을 수행하는 데에 사요한다.
- LLM 모델은 사전에 대규모의 언어 데이터를 학습하여 문장 구조나 문법, 의미 등을 이해하고 생성할 수 있다. 주어진 문맥에서 다음 단어를 예측하는 문제에서 LLM은 문장 내의 단어들 사이의 유사성과 문맥을 파악하여 다음 단어를 생성할 수 있다. 이러한 작업은 기계 번역, 텍스트 요약, 자동 작문, 질문 응답 등 다양한 NLP(자연어 처리) 과제에 활용된다.
- LLM은 GPT 와 BERT 같은 다양한 모델들이 있다.
- GPT vs BERT
  - GPT와 BERT는 둘다 AI가 언어를 이해하고 생성하는데 사용되는 NLP 모델
  - GPT (Generative Pre-trained Transformer)
    - "문장을 보고 다음 단어를 예측하는 AI" ex) "오늘 날씨가" -> "좋다" or "흐리다" 예측
    - GPT의 특징:
      - 텍스트를 생성 하는데 강함
      - 왼쪽에서 오른쪽으로 순차적으로 단어를 예측
      - 챗봇, 에세이 작성, 코드 생성 등에 사용됨
      - 대표 모델:GPT-3, GPT-4
  - BERT (Bidirectional Encoder Representations from Transformers)
    - "문장 전체를 보고 이해하는 AI" ex) "나는 __를 먹었다." -> "사과" or "밥" 예측
    - BERT의 특징:
      - 텍스트의 이해(understanding) 에 강함
      - 앞뒤 문맥을 모두 보고 학습하는 양방향 학습
      - 검색 엔진, 감성 분석, 문장 분류 등에 사용됨
      - 대표 모델: BERT, RoBERTa, ALBERT


    |   GPT             |BERT
----|-------------------|-----------
목적| 문장 생성(텍스트 생성)| 문장 이해 (텍스트 분석)
훈련 방식 | 한 방향(왼쪽 -> 오른쪽) | 양방향 (앞뒤 문맥 활용)
사용 사례 | 챗봇, 문서 작성, 번역, 코드 생성 | 검색, 감정 분석, 문서 요약
대표 모델 | GPT-3, GPT-4, ChatGPT | BERT, RoBERTa, ALBERT

- LLM을 학습 시키는 방법은 대부분 큰 양의 텍스트 데이터를 기계학습 알고리즘에 입력하는 것이다. 이때 일반적으로, 먼저 토큰화와 같은 전처리 과정을 거쳐 문자열 데이터를 분리한 다음, BERT, GPT, T5 등의 모델을 사용하여 학습한다.

### 4. NLP vs LLM
- NLP(Natural Language Processing, 자연어 처리)는 인간이 사용하는 언어를 컴퓨터가 이해하고 처리할 수 있도록 하는 기술 및 연구 분야입니다. 텍스트 및 음성 데이터를 분석, 변환, 생성하는 다양한 방법을 포함하며, 문장 분류, 감정 분석, 번역, 음성 인식, 문서 요약 등의 작업을 수행합니다. NLP는 언어학, 인공 지능, 머신러닝 등의 학문과 밀접하게 관련되어 있습니다.
- LLM(Large Language Model, 대형 언어 모델)은 NLP 기술 중 하나로, 대량의 언어 데이터를 학습하여 특정 NLP 작업을 수행하는 데 초점을 둡니다. LLM은 딥러닝 기반의 신경망 모델을 활용하며, 텍스트 생성, 자동 요약, 코드 작성, 챗봇 운영 등의 작업에 강점을 가집니다. 대표적인 LLM으로는 GPT, BERT, T5, LLaMA, Mistral 등이 있습니다.

즉, NLP는 자연어를 처리하는 전체적인 기술 영역을 포함하는 개념이며, LLM은 그중에서 대량의 데이터로 학습한 딥러닝 기반의 언어 모델을 의미합니다. NLP는 보다 광범위하 ㄴ연구 분야이고, LLM은 구중 특정한 접근 방식과 모델을 가리키는 한 부분입니다.
